{"name":"A look at some Tweets from Thanksgiving 2015","tagline":"A look at some Tweets obtained during Thanksgiving 2015. Analysis done using Apache Zeppelin and the Spark interpreter","body":"# A look at some Tweets from Thanksgiving 2015\r\n\r\n## Overview\r\n***\r\n\r\nI will admit I am a huge fan of Twitter, and of the data it produces because it holds many interesting facts, and opinions of almost any subject from people from all around the world. During Thanksgiving 2015 (November 26), while everyone was eating turkey, I fired up Spark to capture tweets containing the keyword ‘thanksgiving’.\r\n\r\nThe reason I did this work was because I was interested in exploring the tweets generated during that period of time, in particular topics such as the most common retweet, and hashtag. Moreover, I wanted to try Apache Zeppelin, a web-based notebook (similar to iPython or Jupyter) for interactive data analytics.\r\n\r\n## The data\r\n***\r\nThe dataset used is made of 177955 tweets obtained on November 26, 2015.\r\n\r\n## Platforms used\r\n- Apache Zeppelin and the Spark interpreter\r\n- Spark Streaming\r\n- Pig\r\n\r\n## Report\r\n\r\n### Obtaining the data\r\nThe data used for this work was obtained using Spark Streaming, and its Twitter library. The script written captured only the text component of the tweet, in other word, just the tweet itself. After an hour or so of capturing tweets, I ended up with a directory made of many subdirectories that had the tweets. Because of this, a Pig script was written to transfer the content of all these files into a single one. Both of these scripts are on the GitHub repository.\r\n\r\n### The result\r\n\r\nOnce the data was in the wanted format, it was loaded into Zeppelin. Keep in mind that I was using the Spark interpreter, meaning that the syntax you will see in the following images are Spark code, or Pyspark to be more specific.\r\n\r\nThe following images shows how the data was loaded, and the number of tweets available in the dataset, 177955.\r\n\r\n![load](http://juandes.github.io/thanksgiving-tweets/images/loaddata_numbertweets.png)\r\n\r\nAfter counting the number of tweets, I called the flatMap to get every single word of the corpus, followed by a reduceByKey action to count them - the total number of words is 2145540. Then a new dataframe, made of the words and their frequency, was created. The next image shows the code, followed by two plots of the top 10 words that include the SQL query written to obtain the result. The first image has a comment that says \"get the 20 most common words\", please ignore it (I forgot to remove the comment before taking the screenshots).\r\n\r\n![load](http://juandes.github.io/thanksgiving-tweets/images/word_count.png)\r\n\r\n![load](http://juandes.github.io/thanksgiving-tweets/images/count_1.png)\r\n\r\n![load](http://juandes.github.io/thanksgiving-tweets/images/count_2.png)\r\n\r\nThese are the top 10 words and their frequency\r\n\r\n- **thanksgiving**: 114,556\r\n- **happy**: 103,026\r\n- **rt**: 85,202\r\n- **to**: 59,143\r\n- **the**: 40,918\r\n- **and**: 36,614\r\n- **you**: 31,783\r\n- **a**: 31,105\r\n- **for**: 28,792\r\n- **all**: 28,089\r\n\r\nIs not surprising that the most common words are \"thanksgiving\" and \"happy\".\r\n\r\nSomething really cool about Zeppelin is that you can change the view of the output of an SQL query by just clicking one of the small icons below the query editor. Some of these views include a regular table (as seen on the previous image), a bar chart, a pie chart and others.\r\n\r\nNow that we know what were the most common words, lets do the same but with the hashtags.\r\n\r\nThe next image shows the code used to get the hashtags. Most of the actions performed at this step are similar to those used to find the most common words, the exception in this case is that I used a regex to remove the special characters that follow a hashtag. For example, someone on Twitter might write the hashtag `#thanksgiving!`, but Twitter does not allow numbers or special characters on the hashtags, so the hashtag is just `#thanksgiving` - the `!` is just a normal character of the tweet.\r\n\r\n![hashtags code](http://juandes.github.io/thanksgiving-tweets/images/hashtags_code.png)\r\n\r\nThese are the top 10 hashtags:\r\n\r\n- **#thanksgiving**: 13,716\r\n- **#happythanksgiving**: 1,871\r\n- **#thankful**: 1,350\r\n- **#american**: 677\r\n- **#revealed**: 672\r\n- **#family**: 657\r\n- **#imthankfulfor**: 504\r\n- **#macysparade**: 504 (call me skeptic but I do not like that there are two hashtags with the same count)\r\n- **#blessed**: 380\r\n- **#turkey**: 359\r\n\r\n![hashtags](http://juandes.github.io/thanksgiving-tweets/images/hashtags.png)\r\nSmall note: in this image, the icons of the different plots didn't loaded correctly.\r\n\r\nThere is one hashtag from this list that feels out of place. Do you agree? That is the hashtag `#revealed`. This hashtag belongs to a tweet from an account called `@Drudge_Report` that starts like this \"#REVEALED: What Your #Thanksgiving Feast Does to Your Organs... Avg #American Will Consume 4,500 Cals...\". Mystery solved.\r\n\r\n![revealed](http://juandes.github.io/thanksgiving-tweets/images/revealed.png)\r\n\r\n\r\nSo far we have discovered the top words, and the top hashtags, and now it is time to find the most common mentions.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}